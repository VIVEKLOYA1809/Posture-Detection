{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0aefuIxP_WT",
        "outputId": "0a4720d0-60ae-4124-b7bc-9ab576c4e2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key point detection using Mediapipe\n"
      ],
      "metadata": {
        "id": "gfCi-QyfPMsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o20VJwN0PX7b",
        "outputId": "ac5d49b0-30da-4b0c-a3b8-eabc41c6af41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.3 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose"
      ],
      "metadata": {
        "id": "tfCyRjGeP_5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_output(path):\n",
        "  with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "      image=cv2.imread(path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image.flags.writeable = False\n",
        "\n",
        "      # Make detection\n",
        "      results = pose.process(image)\n",
        "\n",
        "      # Recolor back to BGR\n",
        "      image.flags.writeable = True\n",
        "      image = cv2.cvtColor(np.zeros_like(image), cv2.COLOR_RGB2BGR)\n",
        "      landmarks=results.pose_landmarks.landmark\n",
        "      return landmarks"
      ],
      "metadata": {
        "id": "bUUMAwuGRb55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random as r\n",
        "files = []\n",
        "for dirname, dir, filenames in os.walk('/content/drive/MyDrive/YogaDataset/TRAIN'):\n",
        "    for filename in filenames:\n",
        "        files.append(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "2AMF-piVP_T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_test = []\n",
        "for dirname, dir, filenames in os.walk('/content/drive/MyDrive/YogaDataset/TEST'):\n",
        "    for filename in filenames:\n",
        "        files_test.append(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "fP2BpCgOQBHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train={}\n",
        "for path in files:\n",
        "  keypoint=[]\n",
        "  try:\n",
        "    landmarks=final_output(path)\n",
        "    for marks in landmarks:\n",
        "      keypoint.append(marks.x)\n",
        "      keypoint.append(marks.y)\n",
        "    key_points_train[path]=keypoint\n",
        "  except:\n",
        "    print(path) #Mediapipe is not able to detect landmarks on these images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewHmk3TkQIkM",
        "outputId": "352c885d-6821-4aed-b330-ceeec169f35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/YogaDataset/TRAIN/warrior2/00000137.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/warrior2/00000182.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/warrior2/00000189.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/warrior2/00000326.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000147.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000188.png\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000173.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000168.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000212.png\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000224.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000221.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000235.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000220.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000232.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000239.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000270.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000281.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000300.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000304.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000320.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000315.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000322.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000340.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000361.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000350.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000381.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000387.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/downdog/00000367.png\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/plank/00000236.png\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/plank/00000285.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/plank/00000378.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/tree/00000202.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000110.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000146.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000165.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000149.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000204.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000272.png\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000299.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TRAIN/goddess/00000282.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_test={}\n",
        "paths=[]\n",
        "for path in files_test:\n",
        "  keypoint=[]\n",
        "  try:\n",
        "    landmarks=final_output(path)\n",
        "    for marks in landmarks:\n",
        "      keypoint.append(marks.x)\n",
        "      keypoint.append(marks.y)\n",
        "      key_points_test[path]=keypoint\n",
        "  except:\n",
        "    print(path)   #Mediapipe cannot predict landmarks on these test data.\n",
        "    paths.append(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI9Uctc8bOUN",
        "outputId": "ce9ff331-6424-4c4c-a050-a811894db9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/YogaDataset/TEST/warrior2/00000025.png\n",
            "/content/drive/MyDrive/YogaDataset/TEST/warrior2/00000039.png\n",
            "/content/drive/MyDrive/YogaDataset/TEST/downdog/00000010.png\n",
            "/content/drive/MyDrive/YogaDataset/TEST/downdog/00000080.jpg\n",
            "/content/drive/MyDrive/YogaDataset/TEST/downdog/00000120.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "key_points_train_df = pd.DataFrame(columns=[\"key_points\",\"label\"])\n",
        "key_points_test_df = pd.DataFrame(columns=[\"key_points\",\"label\"])"
      ],
      "metadata": {
        "id": "q132nXAqQIpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "for img in key_points_train.keys():\n",
        "    label.append(img.split('/')[6])"
      ],
      "metadata": {
        "id": "qZ906ECYfcZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df.loc[:,\"key_points\"]=key_points_train.values() #only assigning the images on which landmarks are detected\n",
        "key_points_train_df.loc[:,\"label\"]=label"
      ],
      "metadata": {
        "id": "fAT0znU6bIlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = pd.get_dummies(key_points_train_df['label'], prefix='label')\n",
        "key_points_train_df = pd.concat([key_points_train_df, one_hot], axis=1)"
      ],
      "metadata": {
        "id": "Sn5N6RoPSYC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "key_points_train_df['label_code'] = le.fit_transform(key_points_train_df['label'])"
      ],
      "metadata": {
        "id": "HMxGTNzwYrPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df.drop(columns=['label'],inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rfj1tuZj9Ktw",
        "outputId": "608c7040-fd6e-4b9e-ddc0-83237ef1952c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             key_points  label_downdog  \\\n",
              "0     [0.364690899848938, 0.1572379767894745, 0.3620...              0   \n",
              "1     [0.44384700059890747, 0.28754690289497375, 0.4...              0   \n",
              "2     [0.44388651847839355, 0.20423871278762817, 0.4...              0   \n",
              "3     [0.44745945930480957, 0.3644116222858429, 0.45...              0   \n",
              "4     [0.5981495380401611, 0.22829404473304749, 0.58...              0   \n",
              "...                                                 ...            ...   \n",
              "1035  [0.48942673206329346, 0.20805078744888306, 0.5...              0   \n",
              "1036  [0.5059691071510315, 0.3123514652252197, 0.516...              0   \n",
              "1037  [0.519749104976654, 0.3131095767021179, 0.5255...              0   \n",
              "1038  [0.4950077533721924, 0.24896344542503357, 0.50...              0   \n",
              "1039  [0.4895409643650055, 0.32919830083847046, 0.49...              0   \n",
              "\n",
              "      label_goddess  label_plank  label_tree  label_warrior2  \n",
              "0                 0            0           0               1  \n",
              "1                 0            0           0               1  \n",
              "2                 0            0           0               1  \n",
              "3                 0            0           0               1  \n",
              "4                 0            0           0               1  \n",
              "...             ...          ...         ...             ...  \n",
              "1035              1            0           0               0  \n",
              "1036              1            0           0               0  \n",
              "1037              1            0           0               0  \n",
              "1038              1            0           0               0  \n",
              "1039              1            0           0               0  \n",
              "\n",
              "[1040 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-295c1d28-a9c2-4e66-8648-7111146f8d32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>key_points</th>\n",
              "      <th>label_downdog</th>\n",
              "      <th>label_goddess</th>\n",
              "      <th>label_plank</th>\n",
              "      <th>label_tree</th>\n",
              "      <th>label_warrior2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.364690899848938, 0.1572379767894745, 0.3620...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.44384700059890747, 0.28754690289497375, 0.4...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.44388651847839355, 0.20423871278762817, 0.4...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.44745945930480957, 0.3644116222858429, 0.45...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.5981495380401611, 0.22829404473304749, 0.58...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035</th>\n",
              "      <td>[0.48942673206329346, 0.20805078744888306, 0.5...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1036</th>\n",
              "      <td>[0.5059691071510315, 0.3123514652252197, 0.516...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1037</th>\n",
              "      <td>[0.519749104976654, 0.3131095767021179, 0.5255...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1038</th>\n",
              "      <td>[0.4950077533721924, 0.24896344542503357, 0.50...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039</th>\n",
              "      <td>[0.4895409643650055, 0.32919830083847046, 0.49...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1040 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-295c1d28-a9c2-4e66-8648-7111146f8d32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-295c1d28-a9c2-4e66-8648-7111146f8d32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-295c1d28-a9c2-4e66-8648-7111146f8d32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0c3805c4-fe3b-4ab8-98ac-7e0798e044cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0c3805c4-fe3b-4ab8-98ac-7e0798e044cb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0c3805c4-fe3b-4ab8-98ac-7e0798e044cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = key_points_train_df['key_points'].apply(pd.Series)\n",
        "key_points_train_df = pd.concat([new_data,key_points_train_df],axis=1)"
      ],
      "metadata": {
        "id": "O8EjjbQtYrj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df=key_points_train_df.drop(columns=['key_points'])\n",
        "# These dataframe have 66 keypoints column and label_encoder and One hot encoder to train for both Random Forest and Neural Network"
      ],
      "metadata": {
        "id": "O5o1ofo15Rg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=66, activation='relu'))   #input layer\n",
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))   #hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=5, activation='softmax')) #output layer with softmax function"
      ],
      "metadata": {
        "id": "cOKa49XB21oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "SArF958t33jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = key_points_train_df.iloc[:,66:-1]\n",
        "X = key_points_train_df.iloc[:,:66]\n",
        "ann.fit(X, y, batch_size = 1, epochs = 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VKTYS0O4Upl",
        "outputId": "a2218cc7-b533-4fcb-8db2-19f1ad4f11f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2477 - accuracy: 0.9106\n",
            "Epoch 2/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2324 - accuracy: 0.9212\n",
            "Epoch 3/50\n",
            "1040/1040 [==============================] - 3s 2ms/step - loss: 0.2391 - accuracy: 0.9154\n",
            "Epoch 4/50\n",
            "1040/1040 [==============================] - 3s 2ms/step - loss: 0.2240 - accuracy: 0.9202\n",
            "Epoch 5/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2046 - accuracy: 0.9260\n",
            "Epoch 6/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2113 - accuracy: 0.9308\n",
            "Epoch 7/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2162 - accuracy: 0.9231\n",
            "Epoch 8/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.2098 - accuracy: 0.9298\n",
            "Epoch 9/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1962 - accuracy: 0.9327\n",
            "Epoch 10/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9375\n",
            "Epoch 11/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1991 - accuracy: 0.9356\n",
            "Epoch 12/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1822 - accuracy: 0.9433\n",
            "Epoch 13/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1827 - accuracy: 0.9433\n",
            "Epoch 14/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1990 - accuracy: 0.9250\n",
            "Epoch 15/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1749 - accuracy: 0.9433\n",
            "Epoch 16/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9317\n",
            "Epoch 17/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1878 - accuracy: 0.9423\n",
            "Epoch 18/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1631 - accuracy: 0.9442\n",
            "Epoch 19/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1614 - accuracy: 0.9433\n",
            "Epoch 20/50\n",
            "1040/1040 [==============================] - 3s 3ms/step - loss: 0.1536 - accuracy: 0.9510\n",
            "Epoch 21/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1595 - accuracy: 0.9538\n",
            "Epoch 22/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1588 - accuracy: 0.9462\n",
            "Epoch 23/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1570 - accuracy: 0.9452\n",
            "Epoch 24/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1513 - accuracy: 0.9481\n",
            "Epoch 25/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1495 - accuracy: 0.9452\n",
            "Epoch 26/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1425 - accuracy: 0.9510\n",
            "Epoch 27/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1643 - accuracy: 0.9452\n",
            "Epoch 28/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1434 - accuracy: 0.9462\n",
            "Epoch 29/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1551 - accuracy: 0.9538\n",
            "Epoch 30/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1392 - accuracy: 0.9558\n",
            "Epoch 31/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1420 - accuracy: 0.9481\n",
            "Epoch 32/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1282 - accuracy: 0.9490\n",
            "Epoch 33/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1376 - accuracy: 0.9606\n",
            "Epoch 34/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1313 - accuracy: 0.9606\n",
            "Epoch 35/50\n",
            "1040/1040 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9500\n",
            "Epoch 36/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1230 - accuracy: 0.9635\n",
            "Epoch 37/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.9567\n",
            "Epoch 38/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1120 - accuracy: 0.9606\n",
            "Epoch 39/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1276 - accuracy: 0.9577\n",
            "Epoch 40/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1330 - accuracy: 0.9577\n",
            "Epoch 41/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1386 - accuracy: 0.9529\n",
            "Epoch 42/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1327 - accuracy: 0.9558\n",
            "Epoch 43/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1025 - accuracy: 0.9692\n",
            "Epoch 44/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1331 - accuracy: 0.9558\n",
            "Epoch 45/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1195 - accuracy: 0.9692\n",
            "Epoch 46/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.0971 - accuracy: 0.9760\n",
            "Epoch 47/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1040 - accuracy: 0.9673\n",
            "Epoch 48/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1153 - accuracy: 0.9654\n",
            "Epoch 49/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1124 - accuracy: 0.9625\n",
            "Epoch 50/50\n",
            "1040/1040 [==============================] - 2s 2ms/step - loss: 0.1122 - accuracy: 0.9644\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f1790fd00>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "y_rf = key_points_train_df['label_code'] #Column with Label encoder\n",
        "clf = RandomForestClassifier(random_state = 42,\n",
        "                             n_jobs = 1,\n",
        "                             n_estimators = 100)"
      ],
      "metadata": {
        "id": "-9IczDEwZCR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X,y_rf)"
      ],
      "metadata": {
        "id": "hrfTkM2jOyPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_t = []\n",
        "for img in key_points_test.keys():\n",
        "    label_t.append(img.split('/')[6])"
      ],
      "metadata": {
        "id": "3PS0wbkxgBfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_test_df.loc[:,\"key_points\"]=key_points_test.values()\n",
        "key_points_test_df.loc[:,\"label\"]=label_t\n",
        "key_points_test_df['label_code'] = le.transform(key_points_test_df['label'])"
      ],
      "metadata": {
        "id": "iE7WL4I-ZCVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_test = key_points_test_df['key_points'].apply(pd.Series)\n",
        "key_points_test_df = pd.concat([new_data_test,key_points_test_df['label_code']],axis=1)"
      ],
      "metadata": {
        "id": "Ivic6rMpZO5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = key_points_test_df['label_code']\n",
        "X_test = key_points_test_df.drop('label_code',axis=1)"
      ],
      "metadata": {
        "id": "kc7mAzgKZO9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = ann.predict(X_test) # prediction with neural network model\n",
        "pred_rf=clf.predict(X_test)      #prediction with random forest classifier"
      ],
      "metadata": {
        "id": "hipNq4kPZaPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f00401-5a9b-4168-f8d4-b67a47822608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=np.argmax(prediction,axis=1)"
      ],
      "metadata": {
        "id": "TnhbrM6L452O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy with NN:\",accuracy_score(y_test,pred))\n",
        "print(\"Accuracy with RFC:\",accuracy_score(y_test,pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYXtznVMZaT2",
        "outputId": "13dcd96f-c385-4257-f5a1-47108d55ddb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9621052631578947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keypoints detection using YOLOV7 model\n"
      ],
      "metadata": {
        "id": "vVScKnw7RqiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/yolov7"
      ],
      "metadata": {
        "id": "vIlYD0MkRaX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression_kpt\n",
        "from utils.plots import output_to_keypoint, plot_skeleton_kpts"
      ],
      "metadata": {
        "id": "6h00NYaARaZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
        "    model.float().eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model.to(device)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "pJE9iA1JRab_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "key_points_dict = {}\n",
        "for img in files:\n",
        "    with torch.no_grad():\n",
        "        ## Transform image from numpy to torch format\n",
        "        image = cv2.imread(img)\n",
        "        image = letterbox(image, 960, stride=64, auto=True)[0]\n",
        "        image = transforms.ToTensor()(image)\n",
        "        image = torch.tensor(np.array([image.numpy()]))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.half().to(device)\n",
        "        model=load_model()\n",
        "        output, _ = model(image)\n",
        "    output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
        "    out1 = output\n",
        "\n",
        "    keypoints = output_to_keypoint(out1)\n",
        "    # iterate for multiple figures in an image\n",
        "    for idx in range(keypoints.shape[0]):\n",
        "        keypoints_list = keypoints[idx,7:].tolist()\n",
        "    key_points_dict[img] = keypoints_list\n",
        "    del image, output\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "R2TazkfTRafn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_df = pd.DataFrame(columns=[\"key_points\",\"label\"])\n",
        "key_points_test = pd.DataFrame(columns=[\"key_points\",\"label\"])"
      ],
      "metadata": {
        "id": "DmqEc_nCRasA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = []\n",
        "for img in key_points_train.keys():\n",
        "    label.append(img.split('/')[6])"
      ],
      "metadata": {
        "id": "Kq7pLv08RauA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df.loc[:,\"key_points\"]=key_points_train.values() #only assigning the images on which landmarks are detected\n",
        "key_points_train_df.loc[:,\"label\"]=label"
      ],
      "metadata": {
        "id": "nrKiYVhVUX-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "key_points_df['label_code'] = le.fit_transform(key_points_df['label'])"
      ],
      "metadata": {
        "id": "Tg69XH2qUt7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = pd.get_dummies(key_points_train_df['label'], prefix='label')\n",
        "key_points_train_df = pd.concat([key_points_train_df, one_hot], axis=1)"
      ],
      "metadata": {
        "id": "frHclZ2VUkRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df=key_points_train_df.drop(columns=['label'])\n",
        "key_points_train_df"
      ],
      "metadata": {
        "id": "eT4oG4_pUkUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = key_points_df['key_points'][:1081].apply(pd.Series)\n",
        "key_points_df = pd.concat([new_data,key_points_df['label_code']],axis=1)"
      ],
      "metadata": {
        "id": "AYnBO0eSRa0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_train_df=key_points_train_df.drop(columns=['key_points'])\n",
        "# These dataframe have 66 keypoints column and label_encoder and One hot encoder to train for both Random Forest and Neural Network"
      ],
      "metadata": {
        "id": "cfq57S6sU5oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=66, activation='relu'))   #input layer\n",
        "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))   #hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=5, activation='softmax')) #output layer with softmax function"
      ],
      "metadata": {
        "id": "z5PSQvAAU5rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "QIoy0M_bU6HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = key_points_train_df.iloc[:,66:-1]\n",
        "X = key_points_train_df.iloc[:,:66]\n",
        "ann.fit(X, y, batch_size = 1, epochs = 50)"
      ],
      "metadata": {
        "id": "oXxSasZNVAM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "y_rf = key_points_train_df['label_code'] #Column with Label encoder\n",
        "clf = RandomForestClassifier(random_state = 42,\n",
        "                             n_jobs = 1,\n",
        "                             n_estimators = 100)"
      ],
      "metadata": {
        "id": "wvVYSPWKVAQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X,y_rf)"
      ],
      "metadata": {
        "id": "YXh4YVdjVApD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_t = []\n",
        "for img in key_points_test.keys():\n",
        "    label_t.append(img.split('/')[6])"
      ],
      "metadata": {
        "id": "JRAiW6FvVAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points_test_df.loc[:,\"key_points\"]=key_points_test.values()\n",
        "key_points_test_df.loc[:,\"label\"]=label_t\n",
        "key_points_test_df['label'] = le.transform(key_points_test_df['label'])"
      ],
      "metadata": {
        "id": "uKMn2FcsVL0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_test = key_points_test_df['key_points'].apply(pd.Series)\n",
        "key_points_test_df = pd.concat([new_data_test,key_points_test_df['label_code']],axis=1)"
      ],
      "metadata": {
        "id": "heFZWaIcVL2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = key_points_test_df['label']\n",
        "X_test = key_points_test_df.drop('label',axis=1)"
      ],
      "metadata": {
        "id": "LPIYOqSDVL6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = ann.predict(X_test) # prediction with neural network model\n",
        "pred_rf=clf.predict(X_test)      #prediction with random forest classifier"
      ],
      "metadata": {
        "id": "zB3VnQWXVSeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=np.argmax(prediction,axis=1)"
      ],
      "metadata": {
        "id": "sSlWVjglVSh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy with NN:\",accuracy_score(y_test,pred))\n",
        "print(\"Accuracy with RFC:\",accuracy_score(y_test,pred_rf))"
      ],
      "metadata": {
        "id": "77mSBNAgVXKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}